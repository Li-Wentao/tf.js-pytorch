{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7ec8c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7b12300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,       # picture size\n",
    "                               out_channels=5,      # KernelSize in tf.js\n",
    "                               kernel_size=3,       # filters in tf.js\n",
    "                               bias=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), \n",
    "                                 stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=5,\n",
    "                               kernel_size=5,\n",
    "                               bias=True)\n",
    "        \n",
    "        # self.fc1 = nn.Linear(5 * 5 * 3, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # x = F.softmax(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fdb0f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c5dc47a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c6a2ee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of Net(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       ")>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc01e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0d297b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i in net.parameters():\n",
    "    ans += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5a1763c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "725d7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4cd3aa",
   "metadata": {},
   "source": [
    "## First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5da7339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kept': False,\n",
       " 'isDisposedInternal': False,\n",
       " 'shape': [3, 3, 1, 5],\n",
       " 'dtype': 'float32',\n",
       " 'size': 45,\n",
       " 'strides': [15, 5, 5],\n",
       " 'dataId': {'id': 0},\n",
       " 'id': 1,\n",
       " 'rankType': '4',\n",
       " 'trainable': True,\n",
       " 'name': 'conv2d_Conv2D1/kernel'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aaa77d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kept': False,\n",
       " 'isDisposedInternal': False,\n",
       " 'shape': [5],\n",
       " 'dtype': 'float32',\n",
       " 'size': 5,\n",
       " 'strides': [],\n",
       " 'dataId': {'id': 1},\n",
       " 'id': 3,\n",
       " 'rankType': '1',\n",
       " 'trainable': True,\n",
       " 'name': 'conv2d_Conv2D1/bias'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "acf24ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "72906918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5882e-01,  8.1480e-02,  1.7400e-01,  9.5683e-03, -1.2598e-01,\n",
       "        -5.7142e-02,  6.9495e-03,  7.7989e-02,  7.2675e-02, -4.6343e-02,\n",
       "        -7.6225e-02,  6.8786e-02,  3.0958e-02,  1.9353e-02, -8.9495e-02,\n",
       "        -1.9291e-02,  1.6426e-01,  9.9582e-02, -1.2810e-01,  1.8971e-02,\n",
       "        -4.6431e-02, -5.8556e-02,  8.2508e-02, -5.7107e-02,  1.4571e-01,\n",
       "         3.8204e-02,  4.8533e-02,  4.4650e-02,  1.8825e-02, -1.3652e-01,\n",
       "        -9.4810e-02, -8.2480e-02,  7.4900e-02, -2.1169e-02,  3.0716e-02,\n",
       "         9.6078e-02,  1.5537e-01,  7.8903e-02, -1.3837e-02,  1.4147e-03,\n",
       "         1.7427e-01,  4.9713e-02, -8.2639e-03,  5.3467e-02,  7.4937e-03,\n",
       "         3.8252e-02, -5.9227e-02,  6.8422e-02,  3.0127e-02, -5.4855e-02,\n",
       "        -1.0487e-01, -2.4225e-02, -1.2204e-01,  1.0031e-01, -6.8431e-02,\n",
       "        -6.5978e-02,  1.2994e-02, -1.9877e-04, -8.2085e-02,  4.1204e-03,\n",
       "        -3.2709e-02, -1.6142e-01,  6.3192e-02, -1.8026e-02,  1.3425e-01,\n",
       "        -1.5689e-01,  1.1534e-01,  3.6959e-02, -9.3848e-02, -5.2178e-02,\n",
       "        -8.1483e-02,  2.3190e-02, -9.1255e-02, -1.0085e-01, -5.7358e-02,\n",
       "         7.1012e-02,  7.3663e-02, -7.3481e-02, -1.2847e-01,  1.3326e-01,\n",
       "        -9.0301e-02, -6.7770e-02, -9.6217e-02, -4.4633e-02, -1.6418e-01,\n",
       "        -1.1113e-01, -1.5357e-02, -1.5668e-01,  2.9475e-02,  9.0624e-02,\n",
       "        -5.1718e-02,  1.1686e-01,  7.4644e-02,  4.2183e-03, -1.0762e-02,\n",
       "         4.8318e-02, -4.0615e-02, -1.0573e-01,  3.7275e-02, -2.4151e-02,\n",
       "        -4.3188e-02,  3.4034e-02, -4.4482e-02, -3.1823e-02, -1.2322e-01,\n",
       "         6.5101e-02, -3.3955e-02, -5.9878e-02,  8.6186e-02, -1.4791e-01,\n",
       "         1.6236e-02, -1.4594e-01,  5.6834e-02,  2.2937e-02,  6.5114e-02,\n",
       "         1.1582e-03,  1.0738e-02,  9.7936e-02,  6.4904e-03, -1.4321e-01,\n",
       "         7.7711e-02, -9.8383e-02,  2.3489e-02,  7.4075e-02, -3.7625e-02,\n",
       "         9.2035e-02,  3.5475e-02,  2.4321e-02,  8.2767e-03,  1.1151e-01,\n",
       "        -1.6454e-01,  9.2373e-02, -1.8982e-02,  6.1672e-02,  4.2221e-02,\n",
       "        -4.7704e-02, -1.2801e-01,  7.1395e-03, -8.9398e-02, -1.1823e-02,\n",
       "         1.4292e-01, -4.4697e-02, -7.0142e-02,  4.0251e-03, -1.2257e-01,\n",
       "         1.5238e-01,  1.2516e-01, -5.3647e-02,  5.9183e-02,  4.0197e-02,\n",
       "         1.6633e-03,  5.5914e-02,  7.2810e-02,  1.0674e-01, -3.2366e-02,\n",
       "         4.6392e-02, -7.7633e-04, -1.7109e-01, -9.8704e-02, -1.3646e-01,\n",
       "        -2.9714e-03,  1.7843e-02,  3.2557e-02,  9.2124e-02, -5.0526e-02,\n",
       "         3.0749e-02,  1.4757e-02, -1.9331e-02,  4.5625e-02, -6.3280e-02,\n",
       "         4.0680e-03,  7.2518e-02, -3.9757e-02, -3.8378e-02,  5.5634e-02,\n",
       "        -1.3443e-01,  1.3220e-02,  3.3919e-02,  1.5931e-01, -7.3207e-02,\n",
       "         7.6837e-02,  1.1797e-01,  2.5636e-02,  7.7900e-02,  1.7141e-01,\n",
       "         1.3373e-02, -4.7468e-02, -1.1719e-01, -3.7102e-02, -2.6874e-04,\n",
       "         1.5298e-01, -6.5882e-02, -1.9381e-02,  6.2246e-03,  3.4182e-03,\n",
       "         9.3220e-02,  6.6015e-02,  3.9969e-02, -4.0914e-03,  4.1389e-02,\n",
       "         4.4693e-02, -3.3610e-02,  5.7997e-02, -1.5283e-01, -3.6141e-02,\n",
       "         2.3145e-02, -1.5626e-02, -5.0955e-02, -6.6682e-02, -2.1677e-02,\n",
       "        -1.1756e-02, -1.1050e-01, -2.8513e-02, -1.1048e-01,  1.7734e-02,\n",
       "         2.0389e-02,  3.9818e-02, -7.2161e-02, -3.7173e-02, -6.8439e-02,\n",
       "         3.3528e-02, -1.5997e-02,  7.1908e-02, -1.2735e-02,  8.4838e-02,\n",
       "        -1.2291e-01, -7.0267e-02,  7.1505e-02, -3.2743e-02, -2.2029e-02,\n",
       "         8.2053e-02, -2.7323e-02, -2.4292e-02, -1.0519e-01,  1.6286e-03,\n",
       "         5.0635e-02, -1.6131e-01,  1.0505e-01,  5.8801e-02, -9.1189e-02,\n",
       "         4.8053e-02, -1.2657e-01, -7.0373e-02,  1.3940e-01,  8.1331e-02,\n",
       "         1.2159e-01,  2.5896e-02,  1.5401e-01,  1.5138e-02, -3.0464e-03,\n",
       "         6.3923e-02,  8.0817e-02,  2.5846e-02,  1.4344e-01, -6.5748e-02,\n",
       "        -5.2039e-02,  1.5398e-01, -1.2372e-01, -1.1286e-02,  1.6325e-01,\n",
       "        -5.3383e-02, -7.1697e-02, -1.0885e-01, -7.0360e-02, -1.5809e-02,\n",
       "        -7.9534e-03, -1.1216e-01,  1.1049e-02,  6.7388e-03, -5.9368e-02,\n",
       "         3.5031e-02, -1.7308e-04,  9.9708e-02,  1.7100e-01,  4.7892e-02,\n",
       "         3.8529e-03, -7.4919e-02, -2.0581e-02, -8.3461e-02,  3.8970e-02,\n",
       "        -5.3808e-02,  7.2799e-02,  2.0711e-02, -2.6480e-03,  1.0819e-01,\n",
       "         3.6777e-02,  3.0920e-02, -3.0479e-02, -9.6468e-02, -1.2966e-02,\n",
       "        -1.2156e-01,  3.6635e-02, -1.4975e-01, -6.4535e-02,  5.4476e-03,\n",
       "         1.3906e-01,  7.6947e-02,  9.1525e-02, -2.1943e-02, -2.6903e-02,\n",
       "        -4.0054e-02, -1.0844e-01, -1.1007e-02, -3.2398e-02,  1.7066e-01,\n",
       "         6.6258e-02,  9.9065e-03,  7.7734e-03, -6.5840e-02,  3.5786e-02,\n",
       "        -1.2712e-02,  1.0762e-01,  3.1235e-02, -5.9999e-02,  9.4141e-02,\n",
       "         7.6761e-02, -6.7709e-02, -1.4216e-03, -1.6989e-01,  2.6213e-03,\n",
       "        -7.7620e-03,  6.6220e-02, -7.6510e-03, -8.8723e-02, -6.8411e-02,\n",
       "        -1.4449e-01,  1.2827e-02,  3.9691e-02, -5.4349e-02,  8.8349e-02,\n",
       "         9.0886e-02, -3.9689e-02, -1.6090e-01,  1.3416e-01, -1.5039e-02,\n",
       "        -1.0154e-01,  2.7010e-02,  1.2117e-01,  1.2286e-01,  1.1163e-01,\n",
       "         2.3374e-02, -1.6252e-02,  5.0844e-02, -4.8484e-02,  1.0473e-01,\n",
       "         1.2488e-01, -5.0530e-02, -9.3527e-02,  1.0128e-01,  2.7009e-02,\n",
       "         2.2307e-02, -1.1286e-02,  8.1599e-02, -1.3636e-02,  1.1956e-01,\n",
       "         3.7866e-02, -5.6448e-03,  5.9834e-02,  4.4411e-02, -1.0336e-01,\n",
       "        -6.2397e-03,  1.1317e-01, -1.9639e-03,  4.3440e-02, -1.0075e-01,\n",
       "        -9.8899e-02,  4.9423e-03, -1.8794e-02, -4.0214e-02,  1.3817e-01,\n",
       "         1.9831e-02,  7.1505e-02, -2.8910e-02,  5.5394e-02, -1.4392e-02,\n",
       "        -6.4002e-03,  1.6273e-01,  1.6160e-01,  9.7039e-02, -1.2397e-02,\n",
       "         4.7250e-02, -8.1975e-02,  5.2575e-02, -2.6921e-03,  2.7952e-02,\n",
       "        -1.8544e-02, -3.9878e-02,  3.7950e-02,  3.8184e-04,  5.4274e-02,\n",
       "        -1.0748e-02, -9.6746e-02, -6.9161e-02,  1.3370e-02,  3.5118e-02,\n",
       "         1.4299e-01, -2.7363e-02,  6.1596e-02,  4.0945e-02,  1.6537e-01,\n",
       "         1.3975e-02,  2.5666e-03,  5.7665e-02, -6.9791e-02,  1.6545e-01,\n",
       "        -3.1744e-02,  1.0725e-01,  2.2119e-02, -2.3424e-02, -1.0459e-01,\n",
       "         6.2066e-03,  2.1284e-02,  1.3135e-02, -5.5121e-02,  1.0660e-01,\n",
       "        -1.2050e-01, -2.3995e-02,  1.0162e-01,  3.3134e-03, -1.3588e-01,\n",
       "        -8.2129e-03, -4.2489e-02, -2.7750e-03,  1.3481e-01, -1.2548e-01,\n",
       "        -5.6582e-02, -1.3019e-02,  1.5569e-01,  1.1990e-01, -3.2839e-02,\n",
       "         2.5056e-03, -4.4343e-03,  5.7900e-02, -1.9720e-02,  1.0730e-03,\n",
       "         1.3814e-01,  1.2959e-01,  5.5574e-02,  3.2262e-02,  1.4233e-02,\n",
       "         4.8379e-02, -6.1313e-02, -1.4384e-01,  6.2747e-02,  1.7246e-01,\n",
       "        -9.6123e-02,  3.2323e-02,  9.6797e-04, -1.0436e-01,  8.8381e-02,\n",
       "         1.2494e-01,  7.8832e-02,  3.9953e-03, -9.9485e-02, -3.6895e-02,\n",
       "        -7.8657e-02,  9.6936e-04, -8.9177e-02, -8.0721e-02,  1.8887e-02,\n",
       "         1.0053e-01,  1.0578e-01,  1.0978e-01, -7.2730e-02,  2.8006e-02,\n",
       "         9.0941e-02, -1.2154e-01,  9.7173e-02,  9.3381e-02,  9.7833e-02,\n",
       "        -9.8740e-02, -3.8081e-02, -4.2280e-02, -1.0626e-01, -1.5554e-01,\n",
       "        -1.6717e-01,  7.0339e-02,  4.0874e-02,  1.0457e-01, -1.6268e-01,\n",
       "        -8.8159e-02,  7.0621e-02,  1.3241e-02, -6.0152e-02,  1.3738e-02,\n",
       "         5.7406e-02,  8.2770e-02,  9.3409e-02,  2.9325e-02,  3.6235e-02,\n",
       "        -1.6759e-01, -9.0713e-03,  4.4946e-02,  9.1603e-02,  1.0830e-02,\n",
       "         5.5628e-02,  6.2112e-02,  9.6992e-03,  8.5334e-02, -8.3210e-02,\n",
       "        -7.7627e-03,  2.0170e-02,  1.0040e-02,  2.4401e-02,  5.9455e-03,\n",
       "        -2.8561e-02, -4.5294e-02, -5.0578e-02, -1.1748e-01,  2.9826e-02,\n",
       "        -8.7403e-02,  9.7847e-02, -9.5133e-02,  3.3087e-02,  3.1443e-02,\n",
       "         2.6918e-02,  6.4361e-02, -5.2307e-02,  7.5512e-02, -1.2608e-01,\n",
       "         4.2280e-02, -9.4247e-02, -1.7100e-01,  1.0548e-01,  1.3919e-01,\n",
       "         1.6325e-01, -9.2166e-02, -4.8994e-02,  1.6912e-01, -8.5366e-02,\n",
       "         1.6245e-01,  8.0507e-02, -2.0124e-02,  1.4201e-01,  6.2779e-03,\n",
       "         5.7156e-02,  1.0003e-01,  1.4101e-01,  3.0188e-02, -4.2759e-02,\n",
       "        -1.2819e-01, -1.0085e-01, -1.2751e-01,  7.0521e-02, -2.3185e-02,\n",
       "        -1.6558e-01, -1.1705e-02,  3.3172e-02, -6.0768e-02, -2.5373e-02,\n",
       "        -1.4413e-01,  1.2057e-01, -4.7153e-02, -7.2973e-02, -1.4510e-01,\n",
       "        -8.4903e-02,  1.1254e-01, -1.4637e-01,  7.6743e-02, -3.9504e-03,\n",
       "         3.0515e-02,  9.5453e-02, -6.4500e-02, -6.1284e-02,  2.8817e-02,\n",
       "         3.7822e-02,  1.3034e-01, -6.2135e-02,  1.4054e-01, -1.3675e-02,\n",
       "        -1.4453e-01, -8.9016e-02,  1.6394e-01,  4.0860e-03, -1.1134e-02,\n",
       "        -9.3072e-03,  6.0730e-02, -1.1438e-01, -1.0374e-01,  1.2443e-01,\n",
       "         3.2222e-02,  3.7422e-03,  4.4408e-02, -1.5355e-01, -1.0805e-01,\n",
       "         2.3990e-02,  1.4830e-01, -8.1154e-03,  1.8973e-02, -5.0975e-02,\n",
       "        -3.9275e-02, -9.2835e-02, -1.4633e-01,  1.0973e-01,  7.0445e-02,\n",
       "        -2.3683e-02, -2.5816e-03, -7.1698e-02,  1.2266e-01, -2.4940e-02,\n",
       "        -8.2053e-02,  6.3046e-02,  3.5892e-02,  1.7806e-02, -8.3118e-02,\n",
       "        -1.2796e-01,  5.3036e-02, -5.3953e-02,  1.0663e-01, -2.7621e-02,\n",
       "        -1.2381e-01, -7.0640e-02,  7.9647e-02, -5.6941e-03,  7.2099e-02,\n",
       "        -5.0440e-02,  5.3145e-02, -5.8394e-02,  7.0239e-02, -1.8095e-02,\n",
       "         6.4901e-02, -5.5345e-02, -7.8664e-02,  4.3301e-02,  9.7112e-03],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(pd.Series(data[2]['params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b043c4",
   "metadata": {},
   "source": [
    "## Fill with params from tf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ee169a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_layer1 = net.state_dict()['conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df6b3401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0986,  0.1083, -0.2065],\n",
       "          [-0.2789,  0.1808,  0.0015],\n",
       "          [ 0.1537,  0.1284,  0.1409]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2220,  0.2002,  0.3052],\n",
       "          [ 0.3021,  0.1051,  0.0257],\n",
       "          [ 0.0373, -0.2939, -0.1135]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1103,  0.0322,  0.1913],\n",
       "          [ 0.2201,  0.1556, -0.2483],\n",
       "          [-0.1437,  0.1202,  0.0885]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2490, -0.2258, -0.2199],\n",
       "          [-0.1441,  0.1782, -0.2386],\n",
       "          [-0.2365,  0.2114, -0.0757]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0310, -0.0406,  0.1733],\n",
       "          [-0.1202, -0.1439,  0.1887],\n",
       "          [ 0.1823,  0.2065, -0.0879]]]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['conv1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "73ebd814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_params_layer1 = torch.tensor(pd.Series(data[0]['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c9d33440",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_input = torch.reshape(tf_params_layer1, shape_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1ba37e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9eac072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = net.state_dict()\n",
    "state_dict['conv1.weight'] = tensor_input\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5f186959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0795,  0.3412, -0.0787],\n",
       "          [-0.2766, -0.1191, -0.3615],\n",
       "          [-0.0822, -0.5693,  0.5850]]],\n",
       "\n",
       "\n",
       "        [[[-0.0629,  0.3145,  0.3474],\n",
       "          [ 0.3322, -0.4905,  0.0166],\n",
       "          [ 0.1015,  0.0281,  0.2332]]],\n",
       "\n",
       "\n",
       "        [[[-0.6460, -0.4513,  0.3746],\n",
       "          [-0.5687,  0.3402, -0.0768],\n",
       "          [ 0.2446,  0.6551,  0.0488]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5565,  0.2835,  0.2720],\n",
       "          [-0.3204,  0.3552,  0.3212],\n",
       "          [-0.0397,  0.5283,  0.3701]]],\n",
       "\n",
       "\n",
       "        [[[-0.1996,  0.1597,  0.3600],\n",
       "          [ 0.2170, -0.1868,  0.1647],\n",
       "          [ 0.3011, -0.4380, -0.5455]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4e65f0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0795,  0.3412, -0.0787],\n",
       "          [-0.2766, -0.1191, -0.3615],\n",
       "          [-0.0822, -0.5693,  0.5850]]],\n",
       "\n",
       "\n",
       "        [[[-0.0629,  0.3145,  0.3474],\n",
       "          [ 0.3322, -0.4905,  0.0166],\n",
       "          [ 0.1015,  0.0281,  0.2332]]],\n",
       "\n",
       "\n",
       "        [[[-0.6460, -0.4513,  0.3746],\n",
       "          [-0.5687,  0.3402, -0.0768],\n",
       "          [ 0.2446,  0.6551,  0.0488]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5565,  0.2835,  0.2720],\n",
       "          [-0.3204,  0.3552,  0.3212],\n",
       "          [-0.0397,  0.5283,  0.3701]]],\n",
       "\n",
       "\n",
       "        [[[-0.1996,  0.1597,  0.3600],\n",
       "          [ 0.2170, -0.1868,  0.1647],\n",
       "          [ 0.3011, -0.4380, -0.5455]]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['conv1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf5b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "012890d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params_from_tf(py_model:nn.Module, tf_model:list):\n",
    "    state_dict = py_model.state_dict()\n",
    "    py_layers = list(state_dict.keys())\n",
    "    tf_layers = [d['model']['name'] for d in tf_model]\n",
    "    tf_params_dict = {d['model']['name'] : torch.tensor(pd.Series(d['params'])) for d in tf_model}\n",
    "    py_nlayers = len(py_layers)\n",
    "    tf_nlayers = len(tf_layers)\n",
    "    if tf_nlayers == py_nlayers:\n",
    "        try:\n",
    "            for py_layer, tf_layer in zip(py_layers, tf_layers):\n",
    "                layer_shape = state_dict[py_layer].shape\n",
    "                params_in = tf_params_dict[tf_layer]\n",
    "                params_in = torch.reshape(params_in, layer_shape)\n",
    "\n",
    "                state_dict[py_layer] = params_in\n",
    "            py_model.load_state_dict(state_dict)\n",
    "        except:\n",
    "            raise Exception(f\"Sorry, model structure did not align in pytorch layer {py_layer}, and tensorflow.js layer {tf_layer}!\")\n",
    "    else:\n",
    "        raise TypeError(\"The model structure of pytorch and tensorflow.js is not aligned! Cannot transfer parameters accordingly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4e84879a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, 3, 5, 5]' is invalid for input of size 625",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/wli17/Dropbox/Start Up/tf2pytorch/Untitled.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wli17/Dropbox/Start%20Up/tf2pytorch/Untitled.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m load_params_from_tf(net, data)\n",
      "\u001b[1;32m/Users/wli17/Dropbox/Start Up/tf2pytorch/Untitled.ipynb Cell 26\u001b[0m in \u001b[0;36mload_params_from_tf\u001b[0;34m(py_model, tf_model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wli17/Dropbox/Start%20Up/tf2pytorch/Untitled.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     layer_shape \u001b[39m=\u001b[39m state_dict[py_layer]\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wli17/Dropbox/Start%20Up/tf2pytorch/Untitled.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     params_in \u001b[39m=\u001b[39m tf_params_dict[tf_layer]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/wli17/Dropbox/Start%20Up/tf2pytorch/Untitled.ipynb#X56sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     params_in \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mreshape(params_in, layer_shape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wli17/Dropbox/Start%20Up/tf2pytorch/Untitled.ipynb#X56sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     state_dict[py_layer] \u001b[39m=\u001b[39m params_in\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wli17/Dropbox/Start%20Up/tf2pytorch/Untitled.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m py_model\u001b[39m.\u001b[39mload_state_dict(state_dict)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[5, 3, 5, 5]' is invalid for input of size 625"
     ]
    }
   ],
   "source": [
    "load_params_from_tf(net, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "150dedd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1d8bd5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv2d_Conv2D1/kernel',\n",
       " 'conv2d_Conv2D1/bias',\n",
       " 'conv2d_Conv2D2/kernel',\n",
       " 'conv2d_Conv2D2/bias']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i['model']['name'] for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "814a9605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv2d_Conv2D1/kernel': tensor([-0.0795,  0.3412, -0.0787, -0.2766, -0.1191, -0.3615, -0.0822, -0.5693,\n",
       "          0.5850, -0.0629,  0.3145,  0.3474,  0.3322, -0.4905,  0.0166,  0.1015,\n",
       "          0.0281,  0.2332, -0.6460, -0.4513,  0.3746, -0.5687,  0.3402, -0.0768,\n",
       "          0.2446,  0.6551,  0.0488,  0.5565,  0.2835,  0.2720, -0.3204,  0.3552,\n",
       "          0.3212, -0.0397,  0.5283,  0.3701, -0.1996,  0.1597,  0.3600,  0.2170,\n",
       "         -0.1868,  0.1647,  0.3011, -0.4380, -0.5455], dtype=torch.float64),\n",
       " 'conv2d_Conv2D1/bias': tensor([0, 0, 0, 0, 0]),\n",
       " 'conv2d_Conv2D2/kernel': tensor([ 1.5882e-01,  8.1480e-02,  1.7400e-01,  9.5683e-03, -1.2598e-01,\n",
       "         -5.7142e-02,  6.9495e-03,  7.7989e-02,  7.2675e-02, -4.6343e-02,\n",
       "         -7.6225e-02,  6.8786e-02,  3.0958e-02,  1.9353e-02, -8.9495e-02,\n",
       "         -1.9291e-02,  1.6426e-01,  9.9582e-02, -1.2810e-01,  1.8971e-02,\n",
       "         -4.6431e-02, -5.8556e-02,  8.2508e-02, -5.7107e-02,  1.4571e-01,\n",
       "          3.8204e-02,  4.8533e-02,  4.4650e-02,  1.8825e-02, -1.3652e-01,\n",
       "         -9.4810e-02, -8.2480e-02,  7.4900e-02, -2.1169e-02,  3.0716e-02,\n",
       "          9.6078e-02,  1.5537e-01,  7.8903e-02, -1.3837e-02,  1.4147e-03,\n",
       "          1.7427e-01,  4.9713e-02, -8.2639e-03,  5.3467e-02,  7.4937e-03,\n",
       "          3.8252e-02, -5.9227e-02,  6.8422e-02,  3.0127e-02, -5.4855e-02,\n",
       "         -1.0487e-01, -2.4225e-02, -1.2204e-01,  1.0031e-01, -6.8431e-02,\n",
       "         -6.5978e-02,  1.2994e-02, -1.9877e-04, -8.2085e-02,  4.1204e-03,\n",
       "         -3.2709e-02, -1.6142e-01,  6.3192e-02, -1.8026e-02,  1.3425e-01,\n",
       "         -1.5689e-01,  1.1534e-01,  3.6959e-02, -9.3848e-02, -5.2178e-02,\n",
       "         -8.1483e-02,  2.3190e-02, -9.1255e-02, -1.0085e-01, -5.7358e-02,\n",
       "          7.1012e-02,  7.3663e-02, -7.3481e-02, -1.2847e-01,  1.3326e-01,\n",
       "         -9.0301e-02, -6.7770e-02, -9.6217e-02, -4.4633e-02, -1.6418e-01,\n",
       "         -1.1113e-01, -1.5357e-02, -1.5668e-01,  2.9475e-02,  9.0624e-02,\n",
       "         -5.1718e-02,  1.1686e-01,  7.4644e-02,  4.2183e-03, -1.0762e-02,\n",
       "          4.8318e-02, -4.0615e-02, -1.0573e-01,  3.7275e-02, -2.4151e-02,\n",
       "         -4.3188e-02,  3.4034e-02, -4.4482e-02, -3.1823e-02, -1.2322e-01,\n",
       "          6.5101e-02, -3.3955e-02, -5.9878e-02,  8.6186e-02, -1.4791e-01,\n",
       "          1.6236e-02, -1.4594e-01,  5.6834e-02,  2.2937e-02,  6.5114e-02,\n",
       "          1.1582e-03,  1.0738e-02,  9.7936e-02,  6.4904e-03, -1.4321e-01,\n",
       "          7.7711e-02, -9.8383e-02,  2.3489e-02,  7.4075e-02, -3.7625e-02,\n",
       "          9.2035e-02,  3.5475e-02,  2.4321e-02,  8.2767e-03,  1.1151e-01,\n",
       "         -1.6454e-01,  9.2373e-02, -1.8982e-02,  6.1672e-02,  4.2221e-02,\n",
       "         -4.7704e-02, -1.2801e-01,  7.1395e-03, -8.9398e-02, -1.1823e-02,\n",
       "          1.4292e-01, -4.4697e-02, -7.0142e-02,  4.0251e-03, -1.2257e-01,\n",
       "          1.5238e-01,  1.2516e-01, -5.3647e-02,  5.9183e-02,  4.0197e-02,\n",
       "          1.6633e-03,  5.5914e-02,  7.2810e-02,  1.0674e-01, -3.2366e-02,\n",
       "          4.6392e-02, -7.7633e-04, -1.7109e-01, -9.8704e-02, -1.3646e-01,\n",
       "         -2.9714e-03,  1.7843e-02,  3.2557e-02,  9.2124e-02, -5.0526e-02,\n",
       "          3.0749e-02,  1.4757e-02, -1.9331e-02,  4.5625e-02, -6.3280e-02,\n",
       "          4.0680e-03,  7.2518e-02, -3.9757e-02, -3.8378e-02,  5.5634e-02,\n",
       "         -1.3443e-01,  1.3220e-02,  3.3919e-02,  1.5931e-01, -7.3207e-02,\n",
       "          7.6837e-02,  1.1797e-01,  2.5636e-02,  7.7900e-02,  1.7141e-01,\n",
       "          1.3373e-02, -4.7468e-02, -1.1719e-01, -3.7102e-02, -2.6874e-04,\n",
       "          1.5298e-01, -6.5882e-02, -1.9381e-02,  6.2246e-03,  3.4182e-03,\n",
       "          9.3220e-02,  6.6015e-02,  3.9969e-02, -4.0914e-03,  4.1389e-02,\n",
       "          4.4693e-02, -3.3610e-02,  5.7997e-02, -1.5283e-01, -3.6141e-02,\n",
       "          2.3145e-02, -1.5626e-02, -5.0955e-02, -6.6682e-02, -2.1677e-02,\n",
       "         -1.1756e-02, -1.1050e-01, -2.8513e-02, -1.1048e-01,  1.7734e-02,\n",
       "          2.0389e-02,  3.9818e-02, -7.2161e-02, -3.7173e-02, -6.8439e-02,\n",
       "          3.3528e-02, -1.5997e-02,  7.1908e-02, -1.2735e-02,  8.4838e-02,\n",
       "         -1.2291e-01, -7.0267e-02,  7.1505e-02, -3.2743e-02, -2.2029e-02,\n",
       "          8.2053e-02, -2.7323e-02, -2.4292e-02, -1.0519e-01,  1.6286e-03,\n",
       "          5.0635e-02, -1.6131e-01,  1.0505e-01,  5.8801e-02, -9.1189e-02,\n",
       "          4.8053e-02, -1.2657e-01, -7.0373e-02,  1.3940e-01,  8.1331e-02,\n",
       "          1.2159e-01,  2.5896e-02,  1.5401e-01,  1.5138e-02, -3.0464e-03,\n",
       "          6.3923e-02,  8.0817e-02,  2.5846e-02,  1.4344e-01, -6.5748e-02,\n",
       "         -5.2039e-02,  1.5398e-01, -1.2372e-01, -1.1286e-02,  1.6325e-01,\n",
       "         -5.3383e-02, -7.1697e-02, -1.0885e-01, -7.0360e-02, -1.5809e-02,\n",
       "         -7.9534e-03, -1.1216e-01,  1.1049e-02,  6.7388e-03, -5.9368e-02,\n",
       "          3.5031e-02, -1.7308e-04,  9.9708e-02,  1.7100e-01,  4.7892e-02,\n",
       "          3.8529e-03, -7.4919e-02, -2.0581e-02, -8.3461e-02,  3.8970e-02,\n",
       "         -5.3808e-02,  7.2799e-02,  2.0711e-02, -2.6480e-03,  1.0819e-01,\n",
       "          3.6777e-02,  3.0920e-02, -3.0479e-02, -9.6468e-02, -1.2966e-02,\n",
       "         -1.2156e-01,  3.6635e-02, -1.4975e-01, -6.4535e-02,  5.4476e-03,\n",
       "          1.3906e-01,  7.6947e-02,  9.1525e-02, -2.1943e-02, -2.6903e-02,\n",
       "         -4.0054e-02, -1.0844e-01, -1.1007e-02, -3.2398e-02,  1.7066e-01,\n",
       "          6.6258e-02,  9.9065e-03,  7.7734e-03, -6.5840e-02,  3.5786e-02,\n",
       "         -1.2712e-02,  1.0762e-01,  3.1235e-02, -5.9999e-02,  9.4141e-02,\n",
       "          7.6761e-02, -6.7709e-02, -1.4216e-03, -1.6989e-01,  2.6213e-03,\n",
       "         -7.7620e-03,  6.6220e-02, -7.6510e-03, -8.8723e-02, -6.8411e-02,\n",
       "         -1.4449e-01,  1.2827e-02,  3.9691e-02, -5.4349e-02,  8.8349e-02,\n",
       "          9.0886e-02, -3.9689e-02, -1.6090e-01,  1.3416e-01, -1.5039e-02,\n",
       "         -1.0154e-01,  2.7010e-02,  1.2117e-01,  1.2286e-01,  1.1163e-01,\n",
       "          2.3374e-02, -1.6252e-02,  5.0844e-02, -4.8484e-02,  1.0473e-01,\n",
       "          1.2488e-01, -5.0530e-02, -9.3527e-02,  1.0128e-01,  2.7009e-02,\n",
       "          2.2307e-02, -1.1286e-02,  8.1599e-02, -1.3636e-02,  1.1956e-01,\n",
       "          3.7866e-02, -5.6448e-03,  5.9834e-02,  4.4411e-02, -1.0336e-01,\n",
       "         -6.2397e-03,  1.1317e-01, -1.9639e-03,  4.3440e-02, -1.0075e-01,\n",
       "         -9.8899e-02,  4.9423e-03, -1.8794e-02, -4.0214e-02,  1.3817e-01,\n",
       "          1.9831e-02,  7.1505e-02, -2.8910e-02,  5.5394e-02, -1.4392e-02,\n",
       "         -6.4002e-03,  1.6273e-01,  1.6160e-01,  9.7039e-02, -1.2397e-02,\n",
       "          4.7250e-02, -8.1975e-02,  5.2575e-02, -2.6921e-03,  2.7952e-02,\n",
       "         -1.8544e-02, -3.9878e-02,  3.7950e-02,  3.8184e-04,  5.4274e-02,\n",
       "         -1.0748e-02, -9.6746e-02, -6.9161e-02,  1.3370e-02,  3.5118e-02,\n",
       "          1.4299e-01, -2.7363e-02,  6.1596e-02,  4.0945e-02,  1.6537e-01,\n",
       "          1.3975e-02,  2.5666e-03,  5.7665e-02, -6.9791e-02,  1.6545e-01,\n",
       "         -3.1744e-02,  1.0725e-01,  2.2119e-02, -2.3424e-02, -1.0459e-01,\n",
       "          6.2066e-03,  2.1284e-02,  1.3135e-02, -5.5121e-02,  1.0660e-01,\n",
       "         -1.2050e-01, -2.3995e-02,  1.0162e-01,  3.3134e-03, -1.3588e-01,\n",
       "         -8.2129e-03, -4.2489e-02, -2.7750e-03,  1.3481e-01, -1.2548e-01,\n",
       "         -5.6582e-02, -1.3019e-02,  1.5569e-01,  1.1990e-01, -3.2839e-02,\n",
       "          2.5056e-03, -4.4343e-03,  5.7900e-02, -1.9720e-02,  1.0730e-03,\n",
       "          1.3814e-01,  1.2959e-01,  5.5574e-02,  3.2262e-02,  1.4233e-02,\n",
       "          4.8379e-02, -6.1313e-02, -1.4384e-01,  6.2747e-02,  1.7246e-01,\n",
       "         -9.6123e-02,  3.2323e-02,  9.6797e-04, -1.0436e-01,  8.8381e-02,\n",
       "          1.2494e-01,  7.8832e-02,  3.9953e-03, -9.9485e-02, -3.6895e-02,\n",
       "         -7.8657e-02,  9.6936e-04, -8.9177e-02, -8.0721e-02,  1.8887e-02,\n",
       "          1.0053e-01,  1.0578e-01,  1.0978e-01, -7.2730e-02,  2.8006e-02,\n",
       "          9.0941e-02, -1.2154e-01,  9.7173e-02,  9.3381e-02,  9.7833e-02,\n",
       "         -9.8740e-02, -3.8081e-02, -4.2280e-02, -1.0626e-01, -1.5554e-01,\n",
       "         -1.6717e-01,  7.0339e-02,  4.0874e-02,  1.0457e-01, -1.6268e-01,\n",
       "         -8.8159e-02,  7.0621e-02,  1.3241e-02, -6.0152e-02,  1.3738e-02,\n",
       "          5.7406e-02,  8.2770e-02,  9.3409e-02,  2.9325e-02,  3.6235e-02,\n",
       "         -1.6759e-01, -9.0713e-03,  4.4946e-02,  9.1603e-02,  1.0830e-02,\n",
       "          5.5628e-02,  6.2112e-02,  9.6992e-03,  8.5334e-02, -8.3210e-02,\n",
       "         -7.7627e-03,  2.0170e-02,  1.0040e-02,  2.4401e-02,  5.9455e-03,\n",
       "         -2.8561e-02, -4.5294e-02, -5.0578e-02, -1.1748e-01,  2.9826e-02,\n",
       "         -8.7403e-02,  9.7847e-02, -9.5133e-02,  3.3087e-02,  3.1443e-02,\n",
       "          2.6918e-02,  6.4361e-02, -5.2307e-02,  7.5512e-02, -1.2608e-01,\n",
       "          4.2280e-02, -9.4247e-02, -1.7100e-01,  1.0548e-01,  1.3919e-01,\n",
       "          1.6325e-01, -9.2166e-02, -4.8994e-02,  1.6912e-01, -8.5366e-02,\n",
       "          1.6245e-01,  8.0507e-02, -2.0124e-02,  1.4201e-01,  6.2779e-03,\n",
       "          5.7156e-02,  1.0003e-01,  1.4101e-01,  3.0188e-02, -4.2759e-02,\n",
       "         -1.2819e-01, -1.0085e-01, -1.2751e-01,  7.0521e-02, -2.3185e-02,\n",
       "         -1.6558e-01, -1.1705e-02,  3.3172e-02, -6.0768e-02, -2.5373e-02,\n",
       "         -1.4413e-01,  1.2057e-01, -4.7153e-02, -7.2973e-02, -1.4510e-01,\n",
       "         -8.4903e-02,  1.1254e-01, -1.4637e-01,  7.6743e-02, -3.9504e-03,\n",
       "          3.0515e-02,  9.5453e-02, -6.4500e-02, -6.1284e-02,  2.8817e-02,\n",
       "          3.7822e-02,  1.3034e-01, -6.2135e-02,  1.4054e-01, -1.3675e-02,\n",
       "         -1.4453e-01, -8.9016e-02,  1.6394e-01,  4.0860e-03, -1.1134e-02,\n",
       "         -9.3072e-03,  6.0730e-02, -1.1438e-01, -1.0374e-01,  1.2443e-01,\n",
       "          3.2222e-02,  3.7422e-03,  4.4408e-02, -1.5355e-01, -1.0805e-01,\n",
       "          2.3990e-02,  1.4830e-01, -8.1154e-03,  1.8973e-02, -5.0975e-02,\n",
       "         -3.9275e-02, -9.2835e-02, -1.4633e-01,  1.0973e-01,  7.0445e-02,\n",
       "         -2.3683e-02, -2.5816e-03, -7.1698e-02,  1.2266e-01, -2.4940e-02,\n",
       "         -8.2053e-02,  6.3046e-02,  3.5892e-02,  1.7806e-02, -8.3118e-02,\n",
       "         -1.2796e-01,  5.3036e-02, -5.3953e-02,  1.0663e-01, -2.7621e-02,\n",
       "         -1.2381e-01, -7.0640e-02,  7.9647e-02, -5.6941e-03,  7.2099e-02,\n",
       "         -5.0440e-02,  5.3145e-02, -5.8394e-02,  7.0239e-02, -1.8095e-02,\n",
       "          6.4901e-02, -5.5345e-02, -7.8664e-02,  4.3301e-02,  9.7112e-03],\n",
       "        dtype=torch.float64),\n",
       " 'conv2d_Conv2D2/bias': tensor([0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{d['model']['name'] : torch.tensor(pd.Series(d['params'])) for d in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e231b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f1b901f5ef336371c4da605f62eabd2b49932aa18e426666bd71ae90942cd54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
